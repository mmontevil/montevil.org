---
excerpt: Critical phenomena disrupt the mathematical determination at a given level, which leads to a new perspective on levels of organization.
---
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><a id="h1"></a>
<h2 class="titleHead" id="from-bottom-up-approaches-to-levels-of-organization-and-extended-critical-transitions">From bottom-up approaches to levels of organization and extended critical transitions</h2>
<div class="authors" style="text-align:center">Giuseppe Longo<sup>1,2</sup>*, <a href="http://www.frontiersin.org/Community/WhosWhoActivity.aspx?sname=MaëlMontévil&amp;UID=36000">Maël Montévil</a><sup>2,3,4</sup>* and Arnaud Pocheville<sup>3,5</sup></div>
<div class="indent center">
  <p><span><sup>1</sup></span> Centre National de la Recherche Scientifique, Centre de Recherche en Épistémologie Appliquée – Polytechnique, Paris, France</p>
  <p><span><sup>2</sup></span> École Normale Supérieure, CIRPHLESS, Paris, France</p>
  <p><span><sup>3</sup></span> École doctorale 474 FDV, Paris 5 Descartes, Paris, France</p>
  <p><span><sup>4</sup></span> Soto and Sonnenschein Lab, Anatomy and cell biology, Tufts University, Boston, MA, USA</p>
  <p><span><sup>5</sup></span> Laboratoire Ecologie and Evolution, École normale supérieure, Centre National de la Recherche Scientifique, UMR 7625, Paris, France</p>
</div>
<div class="indent">
  <p class="paragraphHead">Abstract</p>
  <p>
    Biological thinking is structured by the notion of level of organization. We will show that this notion acquires a precise meaning in critical phenomena: they disrupt, by the appearance of infinite quantities, the mathematical (possibly
    equational) determination at a given level, when moving at an “higher” one. As a result, their analysis cannot be called genuinely bottom-up, even though it remains upward in a restricted sense. At the same time, criticality and related
    phenomena are very common in biology. Because of this, we claim that bottom-up approaches are not sufficient, in principle, to capture biological phenomena. In the second part of this paper, following (<a href="#B3">Bailly, 1991b</a>),
    we discuss a strong criterium of level transition. The core idea of the criterium is to start from the breaking of the symmetries and determination at a “first” level in order to “move” at the others. If biological phenomena have
    multiple, <i>sustained</i> levels of organization in this sense, then they should be interpreted as <i>extended</i> critical transitions.
  </p>
</div>
<p class="indent"><span class="paragraphHead">Keywords:</span> bottom-up, extended criticality, renormalization, levels of organization, singularity, organism</p>
<div class="clear">
  <h3 class="sectionHead" id="table-of-contents">Table of contents</h3>
  <ul class="tableofcontents nav nav-list list-unstyled contents">
    <li><a href="#h1">Abstract</a></li>
    <li><a href="#h2">1. Introduction</a></li>
    <li><a href="#h3">2. Critical Phenomena and Bottom-Up Approaches</a></li>
    <li><a href="#h4">3. Levels of Organizations</a></li>
    <li><a href="#h5">4. Application to Biology</a></li>
    <li><a href="#h6">Conclusion</a></li>
    <li><a href="#h7">Conflict of Interest Statement</a></li>
    <li><a href="#h8">Footnotes</a></li>
    <li><a href="#h9">References</a></li>
  </ul>
</div><a id="h2"></a>
<h3 class="sectionHead" id="1-introduction">1. Introduction</h3>
<p class="indent">
  From our point of view, the topic of this special issue, “Is life a globally critical phenomena, and if so why?” raises a question of <i>principles</i> in theoretical biology. Because of that, we think that this subject goes beyond
  the realm of biophysical models and concepts, which are mostly inherited from physics, and leads to questions that are proper to biological theoretizing.
</p>
<p class="indent">
  There are at least two reasons for considering that biological matter can be considered as a globally critical phenomena. The first reason emerges from the question of the fundamental theoretical symmetries in biology. We examined
  this point in Longo and Montévil (<a href="#B15">2011</a>), <a href="#B16">Longo et al., 2012</a>; see also <a href="#B6">Bailly and Longo, 2011</a>). We will quickly sum up some of our arguments right below for the sake of
  completeness, as they also constitute an answer to the question raised by this special topic. The second reason stems from the intuition that living systems have different “levels of organization.” This is the main aspect our paper
  deals with.
</p>
<p class="indent">
  Let’s first summarize our proposal on the role that symmetries play in biology, by contrast with the situation in physics. In theoretical physics, symmetries are stable: they are the foundation on which the theories are grounded. It
  is fair to say that symmetries allow to constitute theoretical objects. Indeed, theoretical objects in physics are defined by their equational determination and the latter relies on the fact that, for various transformations
  (symmetries) applied to the equations and from the right, well-chosen points of view, the situation remains the <i>same</i> (it is invariant). This invariance is what we call the <i>genericity</i> of physical objects
  <sup id="footnotesuper1"><a id="note1a"></a><a class="footnoteanchor" href="#note1">1</a></sup>. Besides, such an equational determination is valid also because it determines the <i>specific</i> trajectory followed by a given
  object, in principle a “geodetics.”
</p>
<p class="indent">
  By contrast, we proposed in Longo and Montévil (<a href="#B15">2011</a>), <a href="#B16">Longo et al. (2012)</a>, that in biological situations the relevant theoretical symmetries are not stable, but broken by the temporal flow. We
  proposed that this amounts to make the hypothesis that biological objects are specific: their theoretical symmetries change and they <i>become</i> defined/specified along (and by) their history. In other terms, the theoretical
  symmetries change with the flow of time. And, by considering that phase spaces are defined with respect to symmetries, we were lead to the conclusion that there is no stable phase space which would allow to capture or theoretically
  determine the trajectory of a biological object (<a href="#B6">Bailly and Longo, 2011</a>; <a href="#B16">Longo et al., 2012</a>).
</p>
<p class="indent">
  Now, physical critical situations also appear, in particular, when the symmetries of a given object change<sup id="footnotesuper2"><a id="note2a"></a><a class="footnoteanchor" href="#note2">2</a></sup>. However, critical situations
  still pop out from a pre-given phase space, where they appear as a singular point in a background of regular behaviors. By contrast, we claimed that in biology, criticality, in the above sense of symmetry changes, is pervasive, and
  not restricted to points in a predetermined phase space. We called such a situation with pervasive, non-punctual, symmetry changes, an <i>extended critical transition</i> (<a href="#B6">Bailly and Longo, 2011</a>;
  <a href="#B15">Longo and Montévil, 2011</a>; <a href="#B16">Longo et al., 2012</a>). In short, see the references, critical transitions in biology are not confined to a point, as required by the mathematical treatment of physical
  criticality, but to a non-trivial interval of one or more control parameters. Such a situation, we argue, implies a major methodological change with respect to physical theoretizing.
</p>
<p class="indent">
  As we mentioned earlier, there is a second reason to consider that organisms are in extended critical transitions. This reason is based on the notion of levels of organization and on the possibility (or not), to use bottom-up
  approaches in order to understand these systems. Theoretical accounts<sup id="footnotesuper3"><a id="note3a"></a><a class="footnoteanchor" href="#note3">3</a></sup> on living systems are diverse and these accounts crucially depend,
  in particular, on the scale and/or level of study the biologist focuses on (think, for instance, to a molecular approach compared to a tissular or an organismal one). However, when different accounts are meant to deal with what is
  supposed to be the same biological matter, we are faced with the question of pinpointing the relationships between these approaches, and the possibility to understand one scale/level of description in the terms of another, which
  could give the primacy to bottom-up approaches. The first part of this paper deals with this question. The second part deals with the question of the nature of the levels of organization in living systems and provides a strong
  definition of the change of level of organization. We will also explore some theoretical implications of the coexistence of several levels of organization in a living system.
</p>
<p class="indent">
  First, it should be noticed that “scales” and “levels,” despite some laxity in the literature, are not commutable terms. Scales appear through <i>quantities</i> varying in magnitude; they can have the dimensionality of, e.g., space,
  time, energy, mass, etc. By contrast, levels of organization appear through <i>qualitative</i> changes between objects that are organized in a hierarchical manner (for examples atoms, molecules, organelles, cells, organs, organisms,
  etc.). As we will see below, these two notions of scales and levels of organization are not equivalent, especially in biology. As a first example of this difference, we can mention the allometric relationships. These relationships
  describe the change of certain quantities (such as the metabolic rate) through scales (usually measured by the mass), while the level of organization is kept fixed (usually, allometries are drawn at the level of organisms, see for
  example <a href="#B24">Savage et al., 2004</a>).
</p>
<p class="indent">
  In biology, scales are usually not seen as problematic, since they are mostly inherited from physically defined quantities. Contrariwise, the notion of levels of organization, while widely used, appears to be loosely defined, and
  its relevance in principle, beyond mere heuristics, is still a matter of debate (<a href="#B3">Bailly, 1991b</a>; <a href="#B10">Brigandt and Love, 2008</a>). Therefore, in the first part of the paper, we will remain neutral as to
  the notion of level of organization and will restrict ourselves to inter-scale theoretical relationships. To examine this point, we will make a detour through physics, as the conceptual stabilization of this field by mathematization
  makes it easier to clarify conceptual issues. We will then come back to the question of inter-level theoretical relationships, and to the question of their validity in principle.
</p><a id="h3"></a>
<h3 class="sectionHead" id="2-critical-phenomena-and-bottom-up-approaches">2. Critical Phenomena and Bottom-Up Approaches</h3>
<p class="indent">In this part we consider the question of the possibility and the modalities of understanding the whole as a combination of the parts. We will argue that critical phenomena are peculiar with this regard.</p>
<h4 class="subsectionHead" id="21-bottom-up-approaches-in-physics">2.1. Bottom-Up Approaches in Physics</h4>
<p class="indent">
  Here, we do not intend to provide a comprehensive picture of bottom-up approaches in physics. On the contrary, we will focus on situations which are relevant for our purpose. In this field, the question is mainly that of the
  mathematical derivability of the upper-scale determination from the combination of interactions of the parts. The modalities of the integration of the parts will determine if and in what sense bottom-up approaches are used.
</p>
<h5 class="subsubsectionHead" id="211-a-paradigmatic-case-from-molecules-to-thermodynamics">2.1.1. A paradigmatic case: from molecules to thermodynamics</h5>
<p class="indent">
  The main way to understand an upper-scale phenomenon via a lower-scale model is to use some form of statistical averages over the lower-scale properties, provided that the number of lower-scale entities is sufficient. The
  reconstruction of thermodynamics by statistical mechanics is one of the most (supposedly) paradigmatic examples of such a procedure
  <sup id="footnotesuper4"><a id="note4a"></a><a class="footnoteanchor" href="#note4">4</a></sup>.
</p>
<p class="indent">
  The principles of statistical mechanics are the following (see, for example, <a href="#B25">Sethna, 2006</a>). We consider elementary objects (microscopic objects), which live in a given phase space and, therefore, have a state
  which is described in this phase space. A microstate is given by the state of all elementary objects. Each one of these elementary objects has a determined energy function, which depends on its state and on the states of other
  elementary objects (interactions). The sum of all these elementary energetic contributions defines the energy of the considered microstate. Energy, as a function of the state, is called a Hamiltonian (it is a function, not a value).
  The crucial hypothesis is that all microstates with the same energy have equal probability. Therefore, the macroscopic equilibrium state corresponds to the most numerous set of macroscopically similar microscopic states, at fixed
  energy (microcanonical ensemble). This leads to Boltzmann’s interpretation of entropy, where entropy is the logarithm of the number of state at fixed energy. The most probable state is, therefore, the one with the highest entropy.
  Then, the (inverse) temperature can be introduced as a quantity associated to energy (Lagrange multiplier), and the distribution of states follows by generic optimization principle (for a large number of particles). All statistical
  properties are then given by the partition function
  
  <math id="M1">
    <mrow>
      <mi>Z</mi>
      <mo>=</mo>
      <mstyle displaystyle="true">
        <msub>
          <mo>∑</mo>
          <mrow>
            <mi>s</mi>
            <mo>∈</mo>
            <mi>M</mi>
          </mrow>
        </msub>
        <mrow>
          <mi>exp</mi>
          <mo>⁡</mo>
          <mrow>
            <mo>(</mo>
            <mrow>
              <mrow>
                <mrow>
                  <mi>ℋ</mi>
                  <mrow>
                    <mo>(</mo>
                    <mi>s</mi>
                    <mo>)</mo>
                  </mrow>
                </mrow>
                <mo>/</mo>
                <mrow>
                  <msub>
                    <mi>k</mi>
                    <mi>b</mi>
                  </msub>
                  <mi>T</mi>
                </mrow>
              </mrow>
            </mrow>
            <mo>)</mo>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
  </math>
  , where <i>M</i> are the microstates. The probability of each state is
  
  <math id="M2">
    <mrow>
      <mi>exp</mi>
      <mo>⁡</mo>
      <mo stretchy="false">(</mo>
      <mi>ℋ</mi>
      <mo stretchy="false">(</mo>
      <mi>s</mi>
      <mo stretchy="false">)</mo>
      <mo>/</mo>
      <msub>
        <mi>k</mi>
        <mi>b</mi>
      </msub>
      <mi>T</mi>
      <mo stretchy="false">)</mo>
      <mo>/</mo>
      <mi>Z</mi>
    </mrow>
  </math>
  .
</p>
<p class="indent">
  The point is that the distribution depends only on the Hamiltonian, and the conjugated variable, the temperature (when relevant, other parameters can be introduced). Moreover, the thermodynamical quantities can be obtained
  straightforwardly as averages, sums, variance, etc., from this distribution. Mathematically, this is elegantly obtained by elementary operations on <i>Z</i>: differentiation, application of the logarithm, multiplication by the
  inverse temperature, etc. For example, the macroscopic energy is the expected value of the energy of the microstates
  
  <math id="M3">
    <mrow>
      <mrow>
        <mo>〈</mo>
        <mi>E</mi>
        <mo>〉</mo>
      </mrow>
      <mo>=</mo>
      <mo>−</mo>
      <mfrac>
        <mrow>
          <mo>∂</mo>
          <mi>ln</mi>
          <mo>⁡</mo>
          <mi>Z</mi>
        </mrow>
        <mrow>
          <mo>∂</mo>
          <mn>1</mn>
          <mo>/</mo>
          <msub>
            <mi>k</mi>
            <mi>b</mi>
          </msub>
          <mi>T</mi>
        </mrow>
      </mfrac>
      <mo>,</mo>
    </mrow>
  </math>
  see any textbook or <a href="#B25">Sethna (2006)</a> for other examples.
</p>
<p class="indent">
  The probability of deviating from the most probable state decreases exponentially, depending on the number of lower-level entities (this result is known as the fluctuation theorem). Thus, here, the bottom-up approach corresponds to
  the determination of the macrostate by microscopic energies and is, in this case, mathematically achieved and controlled.
</p>
<p class="indent">
  Notice that the elements “include,” in a sense, macroscopic or at least mesoscopics aspects in their mathematical description. The hallmark of this is the dependence on temperature. Similarly, when one approaches the microscopic
  level with classical mechanics, certain notions and hypotheses have to be introduced
  <sup id="footnotesuper5"><a id="note5a"></a><a class="footnoteanchor" href="#note5">5</a></sup>. The main one are the thermodynamic limit (the assumption of an infinite number of particles leads to a coincidence of averages and
  macroscopic states) and the notion of ergodicity (that is a symmetry assumption between time average and phase space average). The latter allows to go from the properties of a trajectory to the properties of the phase space and vice
  versa. Therefore, in both cases, the elements are defined in such a way that they embed the “shadow” of macroscopic aspects. However, and this is the point we want to make, the mathematical situation here is so that it allows to
  fruitfully perform these audacious conceptual operations.
</p>
<h5 class="subsubsectionHead" id="212-when-means-fail-critical-phase-transitions">2.1.2. When means fail: critical phase transitions</h5>
<p class="indent">
  There are some cases in physics where approaches of the kind described above fail. This is particularly the case in some second-order phase transitions, in thermodynamics (
  <a href="#B30">Toulouse et al., 1977</a>).
</p>
<p class="indent">
  An example is as follows: a piece of iron can be considered as composed of a large number of elementary magnets at fixed positions. These elementary magnets tend to be in line with their neighbors (that is the lowest energy state),
  but temperature tends to break down this alignment (it increases the propensity to high energy states). Below a given temperature, the elementary magnets are predominantly aligned, and the piece of iron is globally magnetizable.
  Above this temperature, the thermic agitation is large enough to prevent the elementary magnets to be collectively aligned. The transition between these two behaviors (macroscopic order versus disorder) does not occur progressively
  but at a precise temperature, which defines the critical point. When approaching this point, the correlation lengths tend to infinity, which means that the elementary magnets fluctuate in an increasingly collective manner. At the
  critical point, there are fluctuations at every scale, which means that there is a tendency to obtain magnetic alignments of every size. Moreover, some physical quantities become infinite at the critical point (susceptibility to an
  external field, for example, which is a measure of the effect of an external field going from 0 to ± ∈).
</p>
<p class="indent">But, can a system with fluctuation of any sizes be effectively described by averages?</p>
<p class="indent">
  Landau theory aims to do so. Landau’s strategy is the following: he assumes that we can obtain such a purely macroscopic account and then derives the consequences of this assumption. The latter leads to a first determination of the
  mean of considered variables, and allows to compute the local (in the sense of the correlation length) structure of the fluctuations near the mean
  <sup id="footnotesuper6"><a id="note6a"></a><a class="footnoteanchor" href="#note6">6</a></sup>, when tending toward the critical point. If the means dominate the local behavior, then the approach based on them is valid. However,
  when the fluctuations dominate the local behavior, it implies that they dominate “local” behavior of arbitrary sizes, since we are tending toward the critical point, where the correlation length diverges. In the latter case the
  approach is therefore not consistent.
</p>
<p class="indent">
  The distinction between the mean dominated and the fluctuation dominated situations is given by the Ginzburg criterion (a mathematical criterion, which depends, in particular, on the dimension of space; see
  <a href="#B1">Als-Nielsen and Birgeneau, 1977</a>).
</p>
<p class="indent">
  A related approach to phase transition is the mean-field theory. The basic idea of this approach is to consider microscopic interactions and to replace the non-linear (bilinear typically) interactions between particles by
  interactions with a global parameter representing their mean (e.g., ∑<i>S<sub>i</sub>S<sub>j</sub></i> = ∑<i>S<sub>i</sub>S</i>). This usually leads to consistency equations (given by <i>S</i> = 〈<i>S<sub>i</sub></i>〉). This
  approach, initiated by Landau and Ginzburg, is also clearly related to the validity of the macroscopic, mean parameter. Landau theory can also be technically assimilated to it (Landau theory is in this sense a mean-field theory)
  <sup id="footnotesuper7"><a id="note7a"></a><a class="footnoteanchor" href="#note7">7</a></sup>.
</p>
<p class="indent">
  Thus, for systems undergoing a second-order phase transition, we have a criterion which allows us to determine where bottom-up approaches (here, by the uses of macroscopic means) succeeds. In the preceding section, however, we said
  that the description by statistical mechanics converges nicely when the number of elementary objects increases. Why, then, is this description so badly broken here? The point is that the convergence toward the mean is based on a
  certain independence of the microscopic degrees of freedom, which essentially leads to a statistical convergence (central limit theorem). However, when the fluctuations dominate, we have a coherent mesoscopic structure
  (non-independence). When we approach the critical temperature and the thermodynamic limit simultaneously, we obtain a system whose statistical properties are dominated by fluctuations. Mathematically, this corresponds to
  singularities of the partition function at the critical point and thermodynamic limit, which, therefore, gives infinite quantities for certain statistical quantities (variance typically).
</p>
<p class="indent">
  Systems undergoing second-order phase transition thus fall below the scope of classical bottom-up approaches, since our ability to understand the system (when its elementary components are put together) is undermined by divergences
  generated by their combination.
</p>
<h5 class="subsubsectionHead" id="213-bottom-up-vs-renormalization">2.1.3. Bottom-up vs. renormalization</h5>
<p class="indent">
  We will now examine how systems at a critical point are understood. This will allow us to determine to what extent the theoretical approaches used for these systems can be considered as bottom-up, top-down, or something quite
  different.
</p>
<p class="indent">
  In order to study critical phase transitions, renormalization methods<sup id="footnotesuper8"><a id="note8a"></a><a class="footnoteanchor" href="#note8">8</a></sup> are used. We can describe them as follows. One starts with a system
  described by a model at a given scale (which can be chosen arbitrarily; for instance, one can choose the resolution of the measurement apparatus). This model is composed of a set of parameters and of a function that determines the
  behavior of the system (e.g., the Hamiltonian). Instead of solving the model at this scale, as one usually does, one looks at the way the parameters and functions change when the system is described at an upper-scale. The way models
  change as a function of scales is formalized by a mathematical operator: the renormalization operator.
</p>
<p class="indent">
  In usual cases (like para-ferromagnetic transitions), the model is asymptotically invariant by renormalization. This means that when considering larger scales, the models obtained converge toward a fixed point. Such an asymptotic
  invariance corresponds to scale invariance. In this case, the physical properties of the system are determined by the behavior of the operator in the neighborhood of the fixed point.
</p>
<p class="indent">
  The conceptual meaning of renormalization in critical situations is the following. We cannot mathematically obtain what the combination of elementary constituents leads to, because it generates singularities (at the thermodynamic
  limit), or in other words, because this combination does not converge nicely. In terms of fluctuations, the situation is not tractable because the local behavior is dominated by fluctuations that occur also at scales above the scale
  considered (whatever the latter is). We can nevertheless consider a limited part of the system’s interactions, bounded by arbitrary scale cutoffs. This limited part of interactions is then integrated and the result constitutes one
  of the new elementary parts of a new model. We cannot know what these new elementary components exactly do (solve the model), but we can relate them to the rest of the determination of the system (transform the equations that
  determine the system). In short, since one cannot consider all interactions of the system’s elements, one consider a limited part of these interactions. Then, one mathematically simplify this part, in order to produce a new
  equational determination. This renormalized equations are, however, as complicated as the original one since we have an infinite number of degrees of freedom. In general, the operation is performed in order to
  <i>conserve the equational form of the determination</i>, but with renormalized parameters and variables.
</p>
<p class="indent">
  If some of these parameters vanish asymptotically, when we iterate the procedure, then the fixed point is simpler than the original equation. This procedure can also be applied in the case where the situation is not critical. The
  result is a simplified determination which justifies the smooth behavior obtained by Landau theory, for example. On the contrary, in the case of critical phenomena, which are of interest to us here, the resulting determination (the
  fixed point) remains essentially as complex as the initial one: we do not lose the fluctuations in the process because, as we said earlier, they dominate the behavior of the system at all scales. Why, thus, is this operation still a
  tremendous progress toward the determination of the global behavior of the system under study? When we are at the fixed point, by definition, the iteration of renormalization does not change the equational determination. As we said
  earlier, iterating renormalization consists in taking more interactions into account. Therefore, when we consider the fixed point, we are considering a stabilized situation with respect to the contribution of supplementary
  interactions. When we add interactions to the fixed point, in its renormalization, the changes defined by the renormalization operator takes into account their effects (because we have a fixed point). Therefore, the renormalization
  operator is a description of these interactions. In this sense, asymptotically, <i>all</i> the interactions are images (copies) of the interactions that are taken into account in the renormalization of the fixed point. Therefore, we
  have an <i>explicit</i> account of <i>all the relevant</i> (large scales) interactions in the system<sup id="footnotesuper9"><a id="note9a"></a><a class="footnoteanchor" href="#note9">9</a></sup>, even though this account is not and
  cannot be given by a description at a single scale, that is this account is not an <i>actual</i> combination of all the relevant interactions in the system.
</p>
<p class="indent">
  Finally, it is worth emphasizing that one can consider different models as starting points (possibly but not exclusively at different scales), for if they have the same asymptotic behavior through renormalization, then they lead to
  the same physical properties and are grouped into a unique class of universality (there is an infinity of models in a class of universality since, among a plethora of others, the renormalized model at any scale can be indifferently
  considered as a starting point, <a href="#B14">Lesne, 2003</a>).
</p>
<p class="indent">
  One can consider renormalization methods as a bottom-up approach, given that the study of the system mainly depends on the starting point, which is the lower-scale model. However, this starting point is largely contingent and
  arbitrary, both because one can start from any scale as a minimal scale and because one can change the starting model as long as it remains in the same class of universality. It is in the generic properties of the universality class
  that the objectivity of renormalization lies.
</p>
<p class="indent">
  The renormalization approach has a holistic flavor, in that the local situation at the critical point depends upon the global situation (the coherence structure). Such a coherence structure takes place because correlation lengths
  are infinite. More precisely the system is “so global” that we cannot combine its interactions entirely, we can only, but explicitly, find the form of the contributions of all (large scale) interactions.
</p>
<p class="indent">
  The radically new aspect of renormalization methods is that one does not, <i>stricto sensu</i>, try to solve a model anymore, but rather to know the behavior of the transition from one model to an upper-scale model. In this respect,
  the system is studied at the level of a meta-model: what matters, <i>in fine</i>, is not the intra-model relationships, but the behavior through scales of this inter-model relationship. This meta-model allows to start from a
  subjective model (shaped by approximations and pragmatic constraints) and to reach, through asymptotic properties, objective knowledge about the class of universality and physical properties of the system.
</p>
<p class="indent">
  Quantum field theories deal with situations which also require the use of renormalization methods (where they were actually first invented). The point is that, when we are considering more and more microscopic
  <sup id="footnotesuper10"><a id="note10a"></a><a class="footnoteanchor" href="#note10">10</a></sup> interactions we are faced with divergences (comparable to divergences of critical phenomena). This means that the behavior at a
  scale cannot be given, in this theory, by the contribution of objects of arbitrarily small space scale (this would disrupt the equational structure, by the appearance of infinities). However, we can handle a part of the
  interactions, and consider the stability and the transformations of the equational forms and “constants” when we look at more and more interactions. The possibility for theories to be renormalized is a condition of their theoretical
  validity, here. The point we want to emphasize is that the standard model handles three of the four fundamental physical forces in this manner, where there is no objective smallest, fundamental scale. On the contrary, the
  introduction of a peculiar small scale behavior is in opposition with the manner in which the theory understand microscopic phenomena (<a href="#B33">Zinn-Justin, 2007</a>). Of course, this does not preclude paradigmatic changes,
  especially because the introduction of gravity leads to non-renormalizability (taking more interactions into account leads to a complexification of the equational form, by the introduction of new variables). In this sense, the
  current understanding of microscopic phenomena is <i>bottomless</i> in terms of small scale.
</p>
<p class="indent">
  In short, renormalization allows to provide an explicit (and measurable) account of <i>all</i> relevant interactions in a system when the <i>actual combination</i> of all relevant interactions is mathematically impossible. In other
  words, from the point of view of the theoretical determination, the whole is not the sum of the parts (the sum diverges) but it can be understood by successive partial sums of its parts (which become symmetric to all partial sums of
  parts at large scales). By this and <i>in fine</i>, the whole is not understood by the <i>sum</i> of its parts but by <i>sums</i> of its parts. In the process, the modelization of the microscopic scale appears for a large part
  contingent and arbitrary (and renormalization allows to single out objective aspects from it, that is the invariants of the process). For these reasons, we consider renormalization methods at the edge of bottom-up strategies. These
  methods appear as a mean to go beyond standard bottom-up approaches while keeping a relatively bottom-up flavor (integration of interactions), though a considerably weakened one. In particular, renormalization in quantum field
  theory is associated with a <i>bottomless</i> situation (the small scale behavior cannot be integrated in the sense of an actual combination).
</p>
<h4 class="subsectionHead" id="22-consequences-for-biology">2.2. Consequences for Biology</h4>
<p class="indent">
  Now, what holds for physics does not necessarily hold for biology or, more precisely, does not need to describe “completely” the biological situation. Moreover, physical criticality implies that even a successful physicalism would
  not necessarily mean that we can understand the organism as an <i>actual</i> combination of the interactions between its parts (as usually claimed by adepts of bottom-up approaches).
</p>
<h5 class="subsubsectionHead" id="221-physical-criticality-and-the-living-state-of-matter">2.2.1. Physical criticality and the living state of matter</h5>
<p class="indent">
  Like physical critical systems, biological systems present a complex structure of interactions involving different scales, both in space and time (see for example the case of the heart;
  <a href="#B19">Noble, 2002</a>). Simple collective biological phenomena have experimentally been described as critical in – almost – the physical sense (see <a href="#B18">Mora and Bialek, 2011</a>), for a review of some examples.
  If one considers the question of susceptibilities (sensibility to perturbations), biological transcriptome networks (see <a href="#B26">Shmulevich et al., 2005</a>; <a href="#B21">Nykter et al., 2008</a>), or hair cells (
  <a href="#B11">Camalet et al., 1999</a>) provide good examples. This kind of structure of inter-scale correlations could explain why critical phenomena (more and more) seem pervasive in biology (see for example,
  <a href="#B5">Bailly and Longo, 2008</a>, <a href="#B6">2011</a>; <a href="#B31">Werner, 2010</a>).
</p>
<p class="indent">
  Even molecular biology can provide a somewhat paradoxical example. Indeed, when we abandon the notion of program (and we have substantial reasons for that, see for example
  <a href="#B17">Longo and Tendero, 2007</a>; <a href="#B20">Noble, 2008</a>), and when we look naively at the experimental manipulations performed, we observe that a microscopic experimental manipulations (mutations by substitution,
  for example, concern structures measuring 3.3 Å) can lead to dramatic consequences concerning the whole organism (inasmuch it manages to survive). This implies a considerable amplification of such perturbations over spatial scales.
</p>
<p class="indent">
  Thus, the difficulty found in critical physical situations may well be encountered also in the study of organisms. However, the latter is more difficult since the structure of coherence of an organism is heterogeneous and not
  generally scale-invariant (even though some of its aspects have approximate scale symmetry (see <a href="#B32">West, 2006</a> and the examples above). Here by heterogeneity, we mean that different parts of a system have to be
  described by different theoretical objects (e.g., cells, collagen matrix, capillaries, organs, etc.).
</p>
<p class="indent">
  Another point is that the accounts of biological objects can be different at different scales. This seems to be a crucial difficulty in comparison with the theoretical leverage of scale invariance used for physical critical systems.
  A pragmatic way to overcome this scale dependence is to consider biological systems simultaneously at different scales. This seems indeed to be, <i>de facto</i>, the current approach: biology is a growing field of flourishing
  sub-disciplines (<a href="#B10">Brigandt and Love, 2008</a>). This variety corresponds also to the use of different mathematical techniques (see <a href="#B23">Saetzler et al., 2011</a>).
</p>
<p class="indent">
  The difficulty, when we have critical phenomena in mind, is that the inter-scale relationships are fundamental while the pragmatic point of view tend to consider almost unrelated slices of the phenomena at different scales. From a
  more strictly biological point of view, following (<a href="#B28">Soto et al., 2008</a>; <a href="#B6">Bailly and Longo, 2011</a>), the circular coupling of lower and upper-scales is an essential feature of biological phenomena.
  This coupling is particularly relevant with respect to time, and when one considers its effect along the historical constitution of the organism, during development. <a href="#B9">Bizzarri et al. (2011)</a> also insist that the
  mesoscopic aspects, in particular fractal-like structures are key to understand biological phenomena.
</p>
<h5 class="subsubsectionHead" id="222-conclusion-on-the-consequences-for-biology">2.2.2. Conclusion on the consequences for biology</h5>
<p class="indent">
  Because of these very aspects of biological systems, the renormalization method cannot be used directly (except in some simple situations) and requires at least to be deeply transformed. We will further investigate the application
  of renormalization ideas to biology in a future article. Nevertheless, we can already notice that at least in some cases parts of biological systems behave like physical critical situations and more generally like singular,
  fractal-like structures. Thus, it is fair to assume that biological systems cannot be understood through ordinary bottom-up approaches.
</p>
<h4 class="subsectionHead" id="23-conclusion-of-section-2">2.3. Conclusion of Section 2</h4>
<p class="indent">
  In physics, we have shown that bottom-up (or upward) approaches can lead to at least two different situations. The first corresponds to a validity of the approach of the macroscopic system by usual statistical quantities. The
  second, however, corresponds to genuinely critical situations, where a system builds up a global structure of coherence. In this case, the direct composition of the interactions occurring in the system leads to divergences (when
  going to the thermodynamic limit). Therefore, the situation cannot be studied by the composition of all the interactions in a model. However, the renormalization method nevertheless allows to understand the <i>global</i> structure
  of the interactions because it handles a partial composition of interactions which is symmetric to other compositions of interactions, at larger scales (the sum of all this interactions remains intrinsically divergent). This is also
  combined with a certain contingency and arbitrariness of the initial model of the interactions (as long as it remains in the same class of universality).
</p>
<p class="indent">
  The upward approach, for these reasons, can have a highly counter-intuitive nature in this situation. As we have observed, the determination of the system is not given by the <i>sum</i> of (the determination of) its parts but by
  <i>sums</i> of its parts (in an iterative way). Because certain biological situations have clear empirical critical signatures, the validity of bottom-up approaches in biology cannot be claimed, in full generality, to be stronger
  than this largely weakened version.
</p>
<p class="indent">
  This, however, does not mean that biology can be understood by this form of upward understanding, and an even weaker form, if any, may be required. Indeed, biology seems to imply a finite class of heterogeneous, circularly coupled
  scales, which means, under the hypothesis of criticality, that several scales may be fundamentally relevant and that their co-determination may be a fundamental and constitutive aspect of biology.
</p><a id="h4"></a>
<h3 class="sectionHead" id="3-levels-of-organizations">3. Levels of Organizations</h3>
<p class="indent">
  For the moment, we remained neutral as to whether there are levels of organization in biology, and if there are, what the nature of these levels could be. However, the question of bottom-up approaches in biology is typically framed
  in terms of <i>levels</i> of organization (<a href="#B10">Brigandt and Love, 2008</a>), not only scales. The question of the nature of these theoretical levels is of prime importance to the development of a science of systems, as it
  seems to be the aim of the growing field of systems biology.
</p>
<p class="indent">
  But, if, at first sight, the notion of level of organization seems intuitive, it appears that we still lack objective criteria allowing us to determine what should count as a level or not (
  <a href="#B3">Bailly, 1991b</a>; <a href="#B10">Brigandt and Love, 2008</a>). In particular, we would like to be able to distinguish between the complexification <i>within</i> a given level, and the <i>transition</i> between two
  levels. Indeed, at a given level, we can observe various degrees of complication, corresponding to an accumulation of objects (see below), or, mathematically, to an accumulation of degrees of freedoms or of iterations of a recursive
  function. This question is crucial theoretically, since, for example, there is no obvious reason why certain systems, argued to have fundamental biological relevance, should have an original structure of determination. For example,
  <a href="#B22">Piedrafita et al. (2010)</a> argue that peculiar chemical systems, corresponding to a given circularity criterium, should be a (minimal) model of a fundamental aspect of biological organization. However, since the
  system is written and theoretically handled by usual reaction kinetic theory, it is not clear why the system should be biologically fundamental, and associated to a specific level of organization.
</p>
<p class="indent">
  Here, we first aim at objectivizing the notion of level of organization, following mainly the work of Francis Bailly (<a href="#B4">Bailly et al., 1988</a>;<a href="#B2">Bailly, 1991a</a>, <a href="#B3">b</a>; see also
  <a href="#B6">Bailly and Longo, 2011</a>), adapted to our own understanding.
</p>
<p class="indent">
  Let us first emphasize that, here, we understand a theoretical level of organization in a unusually strong sense. A level of organization will be, in the following, a fundamental level of theoretical determination of objects.
  Typically, in physics, this corresponds to a mathematical frame which determines the specific, theoretical trajectory of a given generic object. Note that, by contrast with
  <a href="#B8">Bitbol (2012)</a>, we do not approach the problem of levels of organization from (nor by a critique of) an ontological viewpoint. On the contrary, we are interested in the possibility, or not, to understand a physical
  or biological situation on the basis of a single level of description by mathematical means. When there is such a possibility, Occam’s Razor applies and we choose the relatively fundamental scale/level of description, from the
  proposed perspective, that is to say the one which enables to derive the others. From a mathematical point of view, the lower-scale/level of description is usually more detailed in the sense that the set of its elementary elements
  usually has more degrees of freedom than the set of elements described at a macroscopic level/scale. Moreover, if these components follow, say, classical trajectories, then the system follows a determined specific trajectory. The
  situation is, therefore, mathematically well determined, and other levels seem confined to have only an analytic relevance. We will see, however, that the situation is not that simple.
</p>
<h4 class="subsectionHead" id="31-complexification-within-a-level">3.1. Complexification within a Level</h4>
<p class="indent">
  Following <a href="#B3">Bailly (1991b)</a>, complexification within a level of organization involves the combinatoric accumulation of objects defined and determined at this level. Accumulation of objects is made possible by the
  generativity of the determination. For example, classical electromagnetism accommodates any charge distribution and their movements. Indeed, most if not all theoretical structures of determination allow to accommodate combinations
  of arbitrarily large (finite) numbers of objects<sup id="footnotesuper11"><a id="note11a"></a><a class="footnoteanchor" href="#note11">11</a></sup>. A fundamental example of such accumulation within a level is an increase in number
  of degrees of freedom, which leads to an accumulation of terms in a Hamiltonian, either independent or corresponding to interactions<sup id="footnotesuper12"><a id="note12a"></a><a class="footnoteanchor" href="#note12">12</a></sup>.
</p>
<p class="indent">
  Theoretical frames yield the pertinent observables and provide the relationships between finite quantities (number of objects, extensive or intensive quantities, time, etc.). This can be seen as the fundamental commensurability of
  the quantities which are involved. This commensurability precisely corresponds to the ability of a frame to provide the theoretical determination of the object described through these quantities. Now, it is crucial to keep in mind
  that the frame itself articulates these quantities, so that also “finiteness” should be understood relatively to it. For example, the integral of a function which is singular (infinite) at a given point can be finite, therefore if
  it is only this integral which is relevant and the systems determination is not disrupted.
</p>
<p class="indent">
  When some <i>relevant</i> quantities become infinite, some fundamental operations can be degenerate (e.g., ∞ + ∞ = ∞) or undefined (e.g., ∞ − ∞ = ?). For example, one usually does not know, by the determination of the system we
  already have, what a physical system will do after a finite time blow up (a situation where the solution becomes infinite in finite time, and is, therefore, interpreted as a break down of the determination if there are physical
  reasons to consider that the considered quantity must remain finite). The crucial point is that, when no relevant infinite quantities are involved, the accumulation of terms does not change the structure of the theoretical frame. In
  quantitative terms, when no infinite quantity is involved, causes and effects remain commensurable (incommensurability would occur typically when the ratio between a cause and an effect becomes infinite).
</p>
<h4 class="subsectionHead" id="32-two-types-of-infinity">3.2. Two Types of Infinity</h4>
<p class="indent">
  It is worth emphasizing that at least two types of infinity should be distinguished. The first deals with the extensive properties (sizes or more precisely the number of objects) and occurs via the
  <i>accumulation</i> of objects within a level. The second deals with the intensive (so to speak “qualitative”) properties of objects and will appear to relate to a change of level. “Intensive” means that the given quantity, in a
  homogeneous system, is independent of the size of the system, and can, therefore, be considered to be a local property (we will come back to this point later). In particular, the ratio between two extensive properties is an
  intensive property. Typical extensive quantities are, in thermodynamics, the volume, the mass, the number of particles, …. On the contrary, intensive quantities are the temperature, concentrations, volumic masses, volumic, or massic
  thermic capacity, …
</p>
<p class="indent">Infinite values have extremely different theoretical meanings whether associated to extensive or intensive quantities.</p>
<ul class="indent">
  <li class="indent">
    With extensive infinity, the theoretical structure of the components is left unchanged, so the whole remains described by the same interactions between the parts. However, it is worth noticing that extensive infinity can transform
    a probabilistic determination of the system into a predictable determination, and thus can change the causal regime (typically, statistics may average). In parallel, extensive infinity can lead to the loss of time reversibility.
    These two modifications of the causal regime (determinism and time irreversibility) are typically encountered in the thermodynamical limit.
  </li>
  <li class="indent">
    By contrast, intensive infinity can disrupt the properties of the parts and, thus, changes the structure of determination of the system (such a disruption typically occurs, in thermodynamics of phase transitions, when the Ginzburg
    criterion is not met, typically when mean-field theory is not valid). Note that, in statistical physics, it is necessary to have extensive infinity for intensive infinity to be obtained (because of the analyticity of the finite size
    partition function).
  </li>
</ul>
<p class="indent">
  It is also interesting to relate these two types of infinities to the question of the theoretical symmetries of a system. We should first keep in mind that symmetries have, in general, a “conservative” nature: they are
  transformations that can be inverted. However, physicists are not really interested in exact solutions. Even though they preserve all the symmetries of the initial hypotheses, they only allow to understand special cases and not
  general features. Let us consider an elementary example to illustrate this point. The classical relaxation equation
  
  <math id="M4">
    <mrow>
      <mfrac>
        <mrow>
          <mi>d</mi>
          <mi>f</mi>
        </mrow>
        <mrow>
          <mi>d</mi>
          <mi>t</mi>
        </mrow>
      </mfrac>
      <mo class="MathClass-rel">=</mo>
      <mo class="MathClass-bin">-</mo>
      <mfrac>
        <mrow>
          <mn>1</mn>
        </mrow>
        <mrow>
          <mi>τ</mi>
        </mrow>
      </mfrac>
      <mi>f</mi>
    </mrow>
  </math>
  corresponds to a situation where the function and its derivative are proportional, which is a symmetry. Physically, this corresponds to a decay that is proportional to the magnitude of the quantity, so that all “small pieces” of the
  corresponding quantity decay independently (think of radioactive disintegration, for example). This symmetry is preserved during the trajectory and never allows the corresponding quantity to disappear completely since the function
  which verifies this symmetry is the exponential
  
  <math id="M5">
    <mrow>
      <mrow>
        <mo class="MathClass-open">(</mo>
        <mrow>
          <mi>f</mi>
          <mrow>
            <mo class="MathClass-open">(</mo>
            <mrow>
              <mi>t</mi>
            </mrow>
            <mo class="MathClass-close">)</mo>
          </mrow>
          <mo class="MathClass-rel">=</mo>
          <mi>f</mi>
          <mrow>
            <mo class="MathClass-open">(</mo>
            <mrow>
              <mn>0</mn>
            </mrow>
            <mo class="MathClass-close">)</mo>
          </mrow>
          <mo class="qopname">exp</mo>
          <mrow>
            <mo class="MathClass-open">(</mo>
            <mrow>
              <mo class="MathClass-bin">-</mo>
              <mfrac>
                <mrow>
                  <mi>t</mi>
                </mrow>
                <mrow>
                  <mi>τ</mi>
                </mrow>
              </mfrac>
            </mrow>
            <mo class="MathClass-close">)</mo>
          </mrow>
        </mrow>
        <mo class="MathClass-close">)</mo>
      </mrow>
    </mrow>
  </math>
  . However, after a time <i>t</i> ≫ τ, the corresponding quantity is extremely small and, for most practical purposes, it is negligible. By the use of infinite time limit, we can break the symmetry of this decreasing exponential and
  replace the value of <i>f</i> by its equilibrium value, 0. This allows to take into account the physically relevant behavior of the system for <i>t</i> ≫ τ, since the classical measure has a finite precision. This kind of reasoning
  is pervasive in physics. For example, renormalization is based on such considerations: it consists in separating relevant and irrelevant components, and the latter vanish at large scales, and, <i>in fine</i>, their objectivity is
  not guaranteed. A more sophisticated situation is the notion of symmetry breaking <i>sensu</i> ( <a href="#B29">Strocchi, 2005</a>), where infinity is required in order to decidedly, physically separate objects corresponding to the
  symmetry breaking (they cannot fluctuate from one macroscopic configuration to another). Another conceptually compelling example is the breaking of time reversibility of the Newtonian frame at the thermodynamic limit.
</p>
<p class="indent">
  Last but not least, infinities should be handled carefully. In particular, when we consider two quantities that go to infinity, the way we approach this combination of infinities matters in general, and one cannot recklessly take
  any limit after the other (the limits do not commute without specific hypothesis). In this case, we usually have a discontinuity of the limit: the behavior at the limit is not the same and not even close to the behaviors near it
  (following another path toward the limit). For example, in the case of criticality, the thermodynamic limit (the number of objects <i>n</i> → ∞) and the singularity associated to criticality (<i>T</i> → <i>T<sub>c</sub></i>) need to
  be taken jointly, via renormalization methods (<a href="#B14">Lesne, 2003</a>). Qualitatively this is natural: the thermodynamic limit allows to define thermodynamic relationships, between macroscopic observables, but at the
  critical point fluctuations at all scale dominate the behavior of the system and a purely macroscopic description is not sufficient.
</p>
<p class="indent">
  One should notice that infinite time, at least in a number of situations, can be assimilated to an extensive infinity (see, for example <a href="#B14">Lesne, 2003</a>). Qualitatively, we have the same role of these two limits (they
  correspond to finding generic trajectories, either by a very long trajectory or through an accumulation of smaller trajectories). Statistically, making 1 random experiment on <i>n</i> independent similar objects, or making
  <i>n</i> successive experiments on a memoryless object are equivalent.
</p>
<h4 class="subsectionHead" id="33-transition-between-two-levels">3.3. Transition between Two Levels</h4>
<p class="indent">
  For a transition between two levels to occur (and not just a complexification within a level), it is necessary to have a change in the parts (or in their relationships). As we already mentioned, such a change seems to only occur
  through the apparition of intensive infinity; however, intensive infinity alone is not sufficient to break the determination of a given level.
</p>
<p class="indent">
  Thermodynamics of second-order phase transition provides a good illustration of when intensive infinity can or cannot lead to a change of level. Landau theory handles critical systems with macroscopic (uniform) variables. This
  account constitutes a first level of determination, but it necessarily produces a singularity at the critical point. In particular, the fluctuations and correlation lengths will diverge. As a result, a first perturbative approach
  <sup id="footnotesuper13"><a id="note13a"></a><a class="footnoteanchor" href="#note13">13</a></sup> will discriminate situations where the mean dominates over the divergent fluctuations (in which case there is no change of level),
  and situations where it is the converse. When divergent fluctuations dominate, the macroscopic relationships blow up, and the theoretician must consider new, relevant objects (via the (semi-)group of renormalization). These objects
  allow to take into account the global structure of coherence associated to the domination of scale-free correlations. The theoretical determination, therefore, operates at a new level.
</p>
<h4 class="subsectionHead" id="34-criteria-of-transition">3.4. Criteria of Transition</h4>
<p class="indent">As a conclusion, we will consider that a transition from a level to another occurs when the two following conditions are met (<a href="#B3">Bailly, 1991b</a>):</p>
<p class="indent">
  1. <i>Transition to infinity</i>: at least one intensive property that is relevant to the first level should be considered as tending to infinity (relevance here means that the given magnitude contributes to the determination of the
  objects).
</p>
<p class="indent">
  2. <i>Change in relevant objects</i>: the fact that the magnitude tends to infinity should make obsolete the empirical and theoretical determinations of the objects. This should introduce new, relevant objects in the system’s
  determination; these objects will be associated to the new level.
</p>
<p class="indent">
  We want to emphasize that this criterion has two fundamental strengths. First, it leads to <i>observable</i> consequences: the divergence of intensive properties. Second, it is based on a break down of the theoretical determination
  of the first level and not on its invalidity for extrinsic reasons. Both of these aspects allow to objectivize the understanding of a situation as constituted by multiple levels of organization.
</p><a id="h5"></a>
<h3 class="sectionHead" id="4-application-to-biology">4. Application to Biology</h3>
<p class="indent">On the basis of the former analysis, we can now discuss levels of organization for biological systems, and the theoretical consequences of the way our definition leads to consider them.</p>
<h4 class="subsectionHead" id="41-biological-levels-of-organization-as-a-hypothesis">4.1. Biological Levels of Organization as a Hypothesis</h4>
<p class="indent">Biological functions typically tie the parts together in an integrated whole. This justifies that biological functions can be intuitively associated with changes of levels of organization.</p>
<p class="indent">
  Therefore, let’s first start with the idea that there are several levels of organization within an organism (we will discuss this intuition below) and take this as an assumption. Because an organism, in general, experiences a range
  of internal and external conditions rather than being confined to a single point, the multiplicity of levels associated to the considered organism should be obtained within an interval of viability parameters (or a dense subset of
  it). Following the aforementioned criteria, the changes of levels of organization are associated to singularities. Therefore, criticality (understood here as singularities in the determination) should be obtained within a dense
  range of parameters, rather than at a single critical point as in usual physical situations. The intuition of multiple levels thus drives us to the hypothesis of an extended criticality of organisms (see also
  <a href="#B2">Bailly, 1991a</a>; <a href="#B5">Bailly and Longo, 2008</a>). In particular, a small effect at a given level can have incommensurable consequences and, therefore, access to an upper level (criterion of intensive
  infinity) within a dense range of a given parameter. This is in particular exemplified by susceptibilities which become infinite and describe the response to an external perturbation.
</p>
<p class="indent">
  Reciprocally, it is clear that if organisms show <i>extended</i> criticality (that is, in the sense of symmetry changes within a dense range of parameters, <i>and</i> with a condition on the strength of the associated fluctuations),
  the multiplicity of levels of organization obtained in the extended critical transition is robust. Integration and regulation, within and by an organism, allow the global robustness in spite of the cascades of instabilities and
  susceptibilities proper to the continual critical transitions of extended criticality.
</p>
<h4 class="subsectionHead" id="42-fractals-and-functions">4.2. Fractals and Functions</h4>
<p class="indent">Let’s consider the hypothesis that biological levels of organization in the above sense are associated to biological functions.</p>
<p class="indent">
  <a href="#B4">Bailly et al. (1988)</a> defended the thesis that the integration of parts within a whole is achieved, in particular, through fractal structures, because fractal structures play a fundamental role in exchanges between
  different media. In our current framework, fractal structures seems indeed to be the simplest structure associated to singularity. It is this singular situation which fulfills our criteria of level transition.
</p>
<p class="indent">Reviewing several biological cases, they made the following hypothesis:</p>
<p class="indent">
  1. to any vital function defined at a given level within an organism (macromolecule, cell, organism), corresponds one structure (active sites, organelles, organs) exhibiting at least one fractal dimension associated to this
  function.
</p>
<p class="indent">2. reciprocally, to any fractal dimension of a structure, corresponds a vital function, which integrates this structure in a whole.</p>
<p class="indent">
  3. moreover, the correspondence between the fractal dimension and the functionality is to be linked with the transition between levels of organization, as fractality enables to make compatible properties that have to be both
  singular and homogeneous (see below).
</p>
<p class="indent"><a href="#B4">Bailly et al. (1988)</a> then proposed to explain the occurrence of fractal structures in organisms by the satisfying of three constraints:</p>
<p class="indent">
  <i>Tendency to maximal proliferation</i>: for instance, the maximization of an exchange surface (to enhance the efficiency and precision of exchanges). This tendency of unbounded growth can be understood by a transition to the
  infinite limit.
</p>
<p class="indent"><i>Steric constraint</i>: the living system is bounded (because of other developmental or evolutionary constraints).</p>
<p class="indent">
  <i>Homogeneity</i>: solution structures should be homogeneous, by which we mean that the singularities should not describe the neighborhood of a point but have to be spread in the relevant space. This constraint excludes solutions
  which fulfill only the two preceding criteria, such as limit points or surface points, where the asymptotic limits would play a particular role. By contrast, fractal solutions are homogeneous (in their singular behavior).
</p>
<p class="indent">
  Examples can be found, for instance, in <a href="#B7">Bassingthwaighte et al. (1994)</a>, <a href="#B32">West (2006)</a>. Typically surfaces of organs or organelles tend to have fractal shapes, with infinite surfaces at the
  mathematical limit. It allows them to have a very high exchange surface with a limited volume. Now, singular behavior are also observed in temporal structures, for example heart rhythm. The latter correspond to the formation of a
  proper temporal structure of coherence, with a unity of the organism extended overtime.
</p>
<p class="indent">
  In the context of an organism, these structures are associated to the functionality of the organs, and participate in constituting the organism as an upper level of organization. The organism is therefore not understood as a
  macroscopic combination of parts, but as constituted by the combination of multiscale, singular structures (which can interact at various scales).
</p>
<h4 class="subsectionHead" id="43-non-genericity-of-parts">4.3. Non-Genericity of Parts</h4>
<p class="indent">
  The conceptual frame we describe leads here to a crucial problem in understanding biological systems. If they are organized in levels, then, in some cases, perturbations can propagate through scales and levels. Thus, if living
  systems are in extended critical transitions, then it is expected that all levels are always “coupled.” This coupling, on one hand, stabilizes (i.e., it contributes to setting the margin of viability or of the extend interval of
  criticality of other levels), on the other it may destabilize the other levels. For example, even objects at the lowest levels (say, macromolecules) do not necessarily follow specific trajectories <i>in vivo</i>, that is to say
  “effective” trajectories (in the system), described by the symmetries at <i>that level</i>. As a consequence, parts do not necessarily exhibit stable enough effective (i.e., in the system) symmetries for us to observe, since these
  symmetries may be broken at the points of level transition and by level interactions. Note also that certain parts are themselves in extended critical transitions (cells, typically).
</p>
<p class="indent">
  A simple example of this feedback of extended criticality on the effective trajectories of parts (which are stable <i>in vitro</i>) is the trajectory of the structure of <i>DNA</i> of living organisms along evolution. The
  evolutionary trajectory of this macromolecule is, in particular, determined by the ability of the organism as such to survive and reproduce in its environment ( <a href="#B16">Longo et al., 2012</a>).
</p>
<p class="indent">
  However, let’s assume that in some cases we can first consider a contingent determination at a level to obtain generic parts. The determination is contingent in that it would be local in time and could be limited, for example, to
  some cellular types, or some cellular history. In particular, this can be the case if we suppose that the rhythm of symmetry breaking is slow enough. Then we would obtain approximately a situation close to usual criticality with
  level transitions.
</p>
<p class="indent">
  Now, with non-generic parts, it is through the stabilization associated to the organism structure that a relative stability of the structure of determination (that is to say, a relative genericity) of parts can be obtained. For
  instance, parts are maintained in their viability zones (by preventing ischemia, providing nutrients, etc.), their proliferation is tempered (
  <a href="#B27">Sonnenschein and Soto, 1999</a>), etc. Also, in general, the determination of cells, for example as given by huge changes like differentiation, is provided in a coupling with the organism (
  <a href="#B28">Soto et al., 2008</a>).
</p><a id="h6"></a>
<h3 class="sectionHead" id="conclusion">Conclusion</h3>
<p class="indent">
  We have seen that bottom-up approaches, understood as the way the parts combine to form the determination of the whole can have at least two decidedly different forms in physics. The first, which is a genuine bottom-up method,
  corresponds to the situation where the determination of the whole can be obtained directly by the combination of the contributions of its parts. The second, where bottom-up approaches reach their limit, corresponds to a situation
  where the determination of the whole diverges and where the formation of global coherent structures takes place. In this case, the theoretical and mathematical way to understand the phenomenon consists in considering partial
  combinations of contributions of parts to the change of the equational determination. In physical critical phenomena, the global structure is thus resolved because all the large scale contributions are <i>symmetrical</i>.
</p>
<p class="indent">
  As for biology, it seems to us that the notion of level of organization is well grounded if a transition between levels corresponds to, at least, a non-genuine bottom-up approach. Following
  <a href="#B3">Bailly (1991b)</a>, we gave a criterion allowing to determine when one can consider that there is a breaking of the determination at one level, which, therefore, corresponds to a transition between two levels. This
  criterion is inspired by the theory of critical phenomena, and is based on the idea of intensive property tending toward infinity breaks the structure of determination. In biology, such singularities are achieved, among other, by
  fractal structures (for instance, the liver tends to have an infinite volumic surface of endoplasmic reticulum). Fractal structures appear to be connective devices (for instance membranes) that link parts together in an integrated
  whole. Singular behaviors are also encountered in temporal and spatio-temporal structures, which can be approximately described by physical methods. We expect, however, that the genuine theoretical scale symmetry of these phenomena
  are not as stable as in physics of critical phenomena (where the invariance of the exponent is sharp).
</p>
<p class="indent">
  We have seen that assuming that living systems are organized in different levels, in the sense of <a href="#B3">Bailly (1991b)</a>, naturally leads to consider that living systems are in extended critical situation. Criticality here
  means that we have strong singularities so that several levels can coexist (for example, when the Ginzburg criterion shows that the mean-field approach fails).
</p>
<p class="indent">
  Now, as we said in introduction, extended criticality has at least two features: continual symmetry changes and different levels of organization. Even though this two features often go together as far as physical criticality is
  concerned, they do not, emph stricto sensu, imply each other. For instance, in the case where Ginzburg criterion legitimates mean-field approaches (<i>d</i> &gt; 4), we have a symmetry change without a strong breaking of the
  structure of the determination. In our view, these two aspects of extended criticality are complementary and jointly contribute to an understanding of biological organisms.
</p>
<p class="indent">
  Extended criticality proposes to describe theoretical objects that have very unusual features in comparison with physical objects. The changes of their theoretical symmetries mean that they are constituted by their history (which is
  not, <i>stricto sensu</i>, a trajectory because the phase space is defined in this process). At the same time, these changes are associated to and allowed by critical singularities, which lead to the continuous formation of several
  levels of organization. The latter are not understood as embedded in each other, like Russian dolls, but, on the contrary, levels in the sense proposed here should be understood as an inter-scale structure, following the coupling of
  the very nature of the parts that concur at the structure of coherence of organisms.
</p><a id="h7"></a>
<h3 class="sectionHead" id="conflict-of-interest-statement">Conflict of Interest Statement</h3>
<p class="indent">The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p><a id="h8"></a>
<h3 class="sectionHead" id="footnotes">Footnotes</h3>
<div class="indent" id="footnotetext">
  <ol>
    <li id="note1">
      <strong><a class="footnotetextanchor" href="#note1a" title>^</a></strong>The fall of Newton’s apple is a pictural representation of that: an apple and a planet are the same object (i.e., they are generic) as regards both
      mechanics and gravitation, but with different parameter’s value (different masses in this case).
    </li>
    <li id="note2">
      <strong><a class="footnotetextanchor" href="#note2a" title>^</a></strong>Indeed, the theoretical determination relies on the available, relevant symmetries, and their change means either that a new quantity appears (via
      fluctuations), or on the contrary that a relevant quantity vanishes and relaxes its constraints on the system (which again leads to fluctuations).
    </li>
    <li id="note3">
      <strong><a class="footnotetextanchor" href="#note3a" title>^</a></strong>We purposely avoid the term “theory” here as theoretical accounts in biology do not (yet?) yield fully integrated theories (
      <a href="#B10">Brigandt and Love, 2008</a>).
    </li>
    <li id="note4">
      <strong><a class="footnotetextanchor" href="#note4a" title>^</a></strong>Note that this example has been challenged, notably as soon as 1961 by <a href="#B13">Feyerabend (1985)</a>, see <a href="#B12">Cat (2007)</a> for a
      review.
    </li>
    <li id="note5">
      <strong><a class="footnotetextanchor" href="#note5a" title>^</a></strong>Because of the novelty of concepts involved in the analytic process, it is tempting to view this process as a unification rather than a reduction.
      In any cases, see <a href="#B12">Cat (2007)</a> for a review of the philosophical positions on unification.
    </li>
    <li id="note6">
      <strong><a class="footnotetextanchor" href="#note6a" title>^</a></strong>It means that we are considering the fluctuations from this mean. The approximation signifies that we are not considering how fluctuations can
      interact with each other and build up even stronger fluctuations.
    </li>
    <li id="note7">
      <strong><a class="footnotetextanchor" href="#note7a" title>^</a></strong>Paradoxically, it is precisely in order to study criticality that mean-field approaches where developed. They thus playa role in the understanding
      of phase transitions, as a first, technically unsophisticated approach, and, of course, are even more useful where they are valid – in our example, in dimensions four and above (see
      <a href="#B1">Als-Nielsen and Birgeneau, 1977</a>).
    </li>
    <li id="note8">
      <strong><a class="footnotetextanchor" href="#note8a" title>^</a></strong>These methods were first used in quantum physics and were successfully transposed in the field of criticality by Wilson, who was awarded the 1982
      Nobel Prize in Physics for this feat. This subject is presented, for example, in <a href="#B30">Toulouse et al. (1977)</a>.
    </li>
    <li id="note9"><strong><a class="footnotetextanchor" href="#note9a" title>^</a></strong>Of course in practice, approximations are usually performed.</li>
    <li id="note10">
      <strong><a class="footnotetextanchor" href="#note10a" title>^</a></strong>The nature of divergences in this domain can be diverse, but we are interested in going from small scales to large scales here. Notice that small
      scale, here, is equivalent to large energy. The reason for this is that the quantum momentum is the spatial derivation operator (associated with the constant <i>h</i>). A small scale behavior means a behavior with a high
      derivative (e.g.,
      
      <math id="M6">
        <mrow>
          <mfrac>
            <mrow>
              <mi>d</mi>
              <mo class="qopname">sin</mo>
              <mrow>
                <mo class="MathClass-open">(</mo>
                <mrow>
                  <mi>x</mi>
                  <mo class="MathClass-bin">∕</mo>
                  <mi>λ</mi>
                </mrow>
                <mo class="MathClass-close">)</mo>
              </mrow>
            </mrow>
            <mrow>
              <mi>d</mi>
              <mi>x</mi>
            </mrow>
          </mfrac>
          <mo class="MathClass-rel">=</mo>
          <mo class="qopname">cos</mo>
          <mrow>
            <mo class="MathClass-open">(</mo>
            <mrow>
              <mi>x</mi>
              <mo class="MathClass-bin">∕</mo>
              <mi>λ</mi>
            </mrow>
            <mo class="MathClass-close">)</mo>
          </mrow>
          <mo class="MathClass-bin">∕</mo>
          <mi>λ</mi>
        </mrow>
      </math>
      ) so that the energy is high. From the field point of view, the classical potential diverge when we are going toward the punctual source of the field.
    </li>
    <li id="note11"><strong><a class="footnotetextanchor" href="#note11a" title>^</a></strong>At least in principle, the analytical tractability in practice depend in particular on the apparition of simplifying symmetries.</li>
    <li id="note12">
      <strong><a class="footnotetextanchor" href="#note12a" title>^</a></strong>It is noteworthy that such combinations are usually associated to a linear aspect (the addition of terms in the Hamiltonian, the superposition of
      states in quantum mechanics and the corresponding unitarity of the Hamiltonian operator, …) and of a non-linearity, corresponding to interactions in the Hamiltonian or measurement in quantum mechanics.
    </li>
    <li id="note13">
      <strong><a class="footnotetextanchor" href="#note13a" title>^</a></strong>That is to say, an approach where we start from the Landau theory but try to specify it by considering fluctuations which do not change the mean
      behavior of the system, obtained in landau theory.
    </li>
  </ol>
</div><a id="h9"></a>
<h3 class="sectionHead" id="references">References</h3>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B1"></a>Als-Nielsen, J., and Birgeneau, R. J. (1977). Mean field theory, the Ginzburg criterion, and marginal dimensionality of phase transitions. <i>Am. J. Phys.</i> 45, 554–560.</p>
  <p class="ReferencesCopy2"><a href="http://dx.doi.org/10.1119/1.11019" target="_blank">CrossRef Full Text</a></p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B2"></a>Bailly, F. (1991a). L’anneau des disciplines. <i>Revue Internationale de Systémique</i> 5.</p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B3"></a>Bailly, F. (1991b). Niveaux d’organisation, changements de niveaux, finalité. <i>Philosophica</i> 47, 31–47.</p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B4"></a>Bailly, F., Gaill, F., and Mosseri, R. (1988). Fonctions biologiques, niveaux d’organisation et dimensions fractales. <i>Revue Internationale de Systémique</i> 2, 295.</p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B5"></a>Bailly, F., and Longo, G. (2008). Extended critical situations: the physical singularity of life phenomena. <i>J. Biol. Syst.</i> 16, 309.</p>
  <p class="ReferencesCopy2"><a href="http://dx.doi.org/10.1142/S0218339008002514" target="_blank">CrossRef Full Text</a></p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B6"></a>Bailly, F., and Longo, G. (2011). <i>Mathematics and the Natural Sciences; The Physical Singularity of Life</i>. London: Imperial College Press. [Preliminary version in French: Hermann, Vision des sciences].</p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B7"></a>Bassingthwaighte, J., Liebovitch, L., and West, B. (1994). <i>Fractal Physiology</i>. New York: American Physiological Society.</p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B8"></a>Bitbol, M. (2012). Downward causation without foundations. <i>Synthese</i> 185, 233–255.</p>
  <p class="ReferencesCopy2"><a href="http://dx.doi.org/10.1007/s11229-010-9723-5" target="_blank">CrossRef Full Text</a></p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B9"></a>Bizzarri, M., Giuliani, A., Cucina, A., D’Anselmi, F., Soto, A. M., and Sonnenschein, C. (2011). Fractal analysis in a systems biology approach to cancer. <i>Semin. Cancer Biol.</i> 21, 175–182.</p>
  <p class="ReferencesCopy2">
    <a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&amp;Cmd=ShowDetailView&amp;TermToSearch=21514387" target="_blank">Pubmed Abstract</a> |
    <a href="http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?db=pubmed&amp;cmd=prlinks&amp;retmode=ref&amp;id=21514387" target="_blank">Pubmed Full Text</a> |
    <a href="http://dx.doi.org/10.1016/j.semcancer.2011.04.002" target="_blank">CrossRef Full Text</a>
  </p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1">
    <a id="B10"></a>Brigandt, I., and Love, A. (2008). <i>Reductionism in Biology</i>. Available at:
    <a href="http://plato.stanford.edu/entries/reduction-biology/">http://plato.stanford.edu/entries/reduction-biology/</a>
  </p>
  <p class="ReferencesCopy2">
    <a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&amp;Cmd=ShowDetailView&amp;TermToSearch=18802777" target="_blank">Pubmed Abstract</a> |
    <a href="http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?db=pubmed&amp;cmd=prlinks&amp;retmode=ref&amp;id=18802777" target="_blank">Pubmed Full Text</a>
  </p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B11"></a>Camalet, S., Duke, T., Julicher, F., and Prost, J. (1999). Auditory sensitivity provided by self-tuned critical oscillations of hair cells. <i>Proc. Natl. Acad. Sci. U.S.A.</i> 97, 3183–3188.</p>
  <p class="ReferencesCopy2"><a href="http://dx.doi.org/10.1073/pnas.97.7.3183" target="_blank">CrossRef Full Text</a></p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1">
    <a id="B12"></a>Cat, J. (2007). <i>The Unity of Science</i>. Available at:
    <a href="http://plato.stanford.edu/entries/scientific-unity/#UniRedLogEmp">http://plato.stanford.edu/entries/scientific-unity/#UniRedLogEmp</a>
  </p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B13"></a>Feyerabend, P. K. (1985). <i>Problems of Empiricism</i>. New York: Cambridge University Press.</p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B14"></a>Lesne, A. (2003). Approches multi-échelles en physique et en biologie. <i>Thèse d’habilitation à diriger des recherches</i>. University Pierre et Marie Curie, Paris.</p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B15"></a>Longo, G., and Montévil, M. (2011). From physics to biology by extending criticality and symmetry breakings. <i>Prog. Biophys. Mol. Biol.</i> 106, 340–347.</p>
  <p class="ReferencesCopy2">
    <a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&amp;Cmd=ShowDetailView&amp;TermToSearch=21419157" target="_blank">Pubmed Abstract</a> |
    <a href="http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?db=pubmed&amp;cmd=prlinks&amp;retmode=ref&amp;id=21419157" target="_blank">Pubmed Full Text</a> |
    <a href="http://dx.doi.org/10.1016/j.pbiomolbio.2011.03.005" target="_blank">CrossRef Full Text</a>
  </p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B16"></a>Longo, G., Montévil, M., and Kauffman, S. (2012). No entailing laws, but enablement in the evolution of the biosphere. <i>Proc. Genet. Evol. Comput. Conf</i>.</p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B17"></a>Longo, G., and Tendero, P.-E. (2007). The differential method and the causal incompleteness of programming theory in molecular biology. <i>Found. Sci.</i> 12, 337–366.</p>
  <p class="ReferencesCopy2"><a href="http://dx.doi.org/10.1007/s10699-007-9111-x" target="_blank">CrossRef Full Text</a></p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B18"></a>Mora, T., and Bialek, W. (2011). Are biological systems poised at criticality? <i>J. Stat. Phys.</i> 144, 268–302.</p>
  <p class="ReferencesCopy2"><a href="http://dx.doi.org/10.1007/s10955-011-0229-4" target="_blank">CrossRef Full Text</a></p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B19"></a>Noble, D. (2002). Modeling the heart – from genes to cells to the whole organ. <i>Science</i> 295, 1678–1682.</p>
  <p class="ReferencesCopy2">
    <a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&amp;Cmd=ShowDetailView&amp;TermToSearch=11872832" target="_blank">Pubmed Abstract</a> |
    <a href="http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?db=pubmed&amp;cmd=prlinks&amp;retmode=ref&amp;id=11872832" target="_blank">Pubmed Full Text</a> |
    <a href="http://dx.doi.org/10.1126/science.1069881" target="_blank">CrossRef Full Text</a>
  </p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B20"></a>Noble, D. (2008). Claude Bernard, the first systems biologist, and the future of physiology. <i>Exp. Physiol.</i> 93, 16–26.</p>
  <p class="ReferencesCopy2">
    <a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&amp;Cmd=ShowDetailView&amp;TermToSearch=17951329" target="_blank">Pubmed Abstract</a> |
    <a href="http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?db=pubmed&amp;cmd=prlinks&amp;retmode=ref&amp;id=17951329" target="_blank">Pubmed Full Text</a> |
    <a href="http://dx.doi.org/10.1113/expphysiol.2007.038695" target="_blank">CrossRef Full Text</a>
  </p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1">
    <a id="B21"></a>Nykter, M., Price, N., Aldana, M., Ramsey, S., Kauffman, S., Hood, L., Yli-Harja, O., and Shmulevich, I. (2008). Gene expression dynamics in the macrophage exhibit criticality.
    <i>Proc. Natl. Acad. Sci. U.S.A.</i> 105, 1897.
  </p>
  <p class="ReferencesCopy2">
    <a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&amp;Cmd=ShowDetailView&amp;TermToSearch=18250330" target="_blank">Pubmed Abstract</a> |
    <a href="http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?db=pubmed&amp;cmd=prlinks&amp;retmode=ref&amp;id=18250330" target="_blank">Pubmed Full Text</a> |
    <a href="http://dx.doi.org/10.1073/pnas.0711525105" target="_blank">CrossRef Full Text</a>
  </p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B22"></a>Piedrafita, G., Montero, F., Morán, F., Cárdenas, M., and Cornish-Bowden, A. (2010). A simple self-maintaining metabolic system: robustness, autocatalysis, bistability. <i>PLoS Comput. Biol.</i> 6, e1000872.</p>
  <p class="ReferencesCopy2">
    <a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&amp;Cmd=ShowDetailView&amp;TermToSearch=20700491" target="_blank">Pubmed Abstract</a> |
    <a href="http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?db=pubmed&amp;cmd=prlinks&amp;retmode=ref&amp;id=20700491" target="_blank">Pubmed Full Text</a> |
    <a href="http://dx.doi.org/10.1371/journal.pcbi.1000872" target="_blank">CrossRef Full Text</a>
  </p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B23"></a>Saetzler, K., Sonnenschein, C., and Soto, A. (2011). Systems biology beyond networks: generating order from disorder through self-organization. <i>Semin. Cancer Biol.</i> 21, 165–174.</p>
  <p class="ReferencesCopy2">
    <a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&amp;Cmd=ShowDetailView&amp;TermToSearch=21569848" target="_blank">Pubmed Abstract</a> |
    <a href="http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?db=pubmed&amp;cmd=prlinks&amp;retmode=ref&amp;id=21569848" target="_blank">Pubmed Full Text</a> |
    <a href="http://dx.doi.org/10.1016/j.semcancer.2011.04.004" target="_blank">CrossRef Full Text</a>
  </p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B24"></a>Savage, V., Gilloly, J., Woodruff, W., West, G., Allen, A., Enquist, B., and Brown, J. (2004). The predominance of quarter-power scaling in biology. <i>Ecology</i> 18, 257–282.</p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B25"></a>Sethna, J. P. (2006). <i>Statistical Mechanics: Entropy, Order Parameters, and Complexity</i>. New York: Oxford University Press.</p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B26"></a>Shmulevich, I., Kauffman, S., and Aldana, M. (2005). Eukaryotic cells are dynamically ordered or critical but not chaotic. <i>Proc. Natl. Acad. Sci. U.S.A.</i> 102, 13439–13444.</p>
  <p class="ReferencesCopy2">
    <a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&amp;Cmd=ShowDetailView&amp;TermToSearch=16155121" target="_blank">Pubmed Abstract</a> |
    <a href="http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?db=pubmed&amp;cmd=prlinks&amp;retmode=ref&amp;id=16155121" target="_blank">Pubmed Full Text</a> |
    <a href="http://dx.doi.org/10.1073/pnas.0506771102" target="_blank">CrossRef Full Text</a>
  </p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B27"></a>Sonnenschein, C., and Soto, A. (1999). <i>The Society of Cells: Cancer and Control of Cell Proliferation</i>. New York: Springer Verlag.</p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B28"></a>Soto, A., Sonnenschein, C., and Miquel, P.-A. (2008). On physicalism and downward causation in developmental and cancer biology. <i>Acta Biotheor.</i> 56, 257–274.</p>
  <p class="ReferencesCopy2">
    <a href="http://www.ncbi.nlm.nih.gov/sites/entrez?Db=pubmed&amp;Cmd=ShowDetailView&amp;TermToSearch=18542843" target="_blank">Pubmed Abstract</a> |
    <a href="http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?db=pubmed&amp;cmd=prlinks&amp;retmode=ref&amp;id=18542843" target="_blank">Pubmed Full Text</a> |
    <a href="http://dx.doi.org/10.1007/s10441-008-9052-y" target="_blank">CrossRef Full Text</a>
  </p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B29"></a>Strocchi, F. (2005). <i>Symmetry Breaking, Volume 732 of Lecture Notes in Physics</i>. Heidelberg: Springer Verlag.</p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B30"></a>Toulouse, G., Pfeuty, P., and Barton, G. (1977). <i>Introduction to the Renormalization Group and to Critical Phenomena</i>. London: Wiley.</p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B31"></a>Werner, G. (2010). Fractals in the nervous system: conceptual implications for theoretical neuroscience. <i>Front. Physiol.</i> 1:15. doi:10.3389/fphys.2010.00015</p>
  <p class="ReferencesCopy2"><a href="http://dx.doi.org/10.3389/fphys.2010.00015" target="_blank">CrossRef Full Text</a></p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B32"></a>West, B. (2006). <i>Where Medicine Went Wrong: Rediscovering the Path to Complexity, Volume 11 of Studies of Nonlinear Phenomena in Life Sciences</i>. Teaneck: World Scientific.</p>
</div>
<div class="bibitem">
  <p class="ReferencesCopy1"><a id="B33"></a>Zinn-Justin, J. (2007). <i>Phase Transitions and Renormalization Group</i>. New York: Oxford University Press.</p>
</div>
